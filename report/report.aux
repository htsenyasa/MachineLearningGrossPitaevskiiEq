\relax 
\providecommand{\transparent@use}[1]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{nielsen2015neural}
\citation{physicsml}
\citation{carleo2017solving}
\citation{cai2017approximating}
\citation{wang2016discovering}
\citation{stoudenmire2016supervised}
\citation{biamonte1611quantum}
\citation{mills2017deep}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:Intro}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Gross Pitaevskii Equation}{1}{section.2}}
\citation{barenghi2016primer}
\citation{barenghi2016primer}
\citation{barenghi2016primer}
\newlabel{eq:GPE_3D}{{1}{2}{Gross Pitaevskii Equation}{equation.2.1}{}}
\newlabel{eq:GPE_inter_param}{{2}{2}{Gross Pitaevskii Equation}{equation.2.2}{}}
\newlabel{GPE_total_energy_general}{{3}{2}{Gross Pitaevskii Equation}{equation.2.3}{}}
\newlabel{GPE_total_energy}{{4}{2}{Gross Pitaevskii Equation}{equation.2.4}{}}
\newlabel{eq:GPE_harmonic_potential}{{5}{2}{Gross Pitaevskii Equation}{equation.2.5}{}}
\newlabel{eq:GPE_time_indep_wave_func}{{6}{2}{Gross Pitaevskii Equation}{equation.2.6}{}}
\newlabel{eq:GPE_time_indep}{{7}{2}{Gross Pitaevskii Equation}{equation.2.7}{}}
\newlabel{eq:GPE_time_indep_wave_func_seperated}{{8}{3}{Gross Pitaevskii Equation}{equation.2.8}{}}
\newlabel{eq:GPE_x_y_wave}{{9}{3}{Gross Pitaevskii Equation}{equation.2.9}{}}
\newlabel{eq:GPE_1D}{{10}{3}{Gross Pitaevskii Equation}{equation.2.10}{}}
\newlabel{eq:GPE_1D_chem_inter}{{11}{3}{Gross Pitaevskii Equation}{equation.2.11}{}}
\newlabel{eq:GPE_dimensionless_length}{{12}{3}{Gross Pitaevskii Equation}{equation.2.12}{}}
\newlabel{eq:GPE_dimensionless_energy}{{13}{3}{Gross Pitaevskii Equation}{equation.2.13}{}}
\newlabel{eq:GPE_dimensionless_without_g}{{14}{3}{Gross Pitaevskii Equation}{equation.2.14}{}}
\citation{dennis2013xmds2}
\citation{muruganandam2009fortran}
\citation{mills2017deep}
\citation{mills2017deep}
\newlabel{eq:GPE_dimensionless_g_1}{{16}{4}{Gross Pitaevskii Equation}{equation.2.16}{}}
\newlabel{eq:GPE_dimensionless_g_2}{{17}{4}{Gross Pitaevskii Equation}{equation.2.17}{}}
\newlabel{eq:GPE_dimensionless}{{18}{4}{Gross Pitaevskii Equation}{equation.2.18}{}}
\newlabel{eq:GPE_no_inter_GSE}{{19}{4}{Gross Pitaevskii Equation}{equation.2.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Numerical Solution and XMDS Framework}{4}{subsection.2.1}}
\citation{zimmermann2011comparison}
\@writefile{toc}{\contentsline {section}{\numberline {3}Problem Statement and Dataset Generation}{5}{section.3}}
\newlabel{sec:Problem statement}{{3}{5}{Problem Statement and Dataset Generation}{section.3}{}}
\newlabel{eq:NU_neuron}{{20}{5}{Problem Statement and Dataset Generation}{equation.3.20}{}}
\newlabel{eq:NU_step_function}{{21}{5}{Problem Statement and Dataset Generation}{equation.3.21}{}}
\citation{nielsen2015neural}
\citation{nielsen2015neural}
\citation{nielsen2015neural}
\citation{nielsen2015neural}
\newlabel{eq:NU_sigma_function}{{22}{6}{Problem Statement and Dataset Generation}{equation.3.22}{}}
\newlabel{eq:NU_neuron_connection}{{23}{6}{Problem Statement and Dataset Generation}{equation.3.23}{}}
\newlabel{eq:NT_Quadratic}{{25}{6}{Problem Statement and Dataset Generation}{equation.3.25}{}}
\newlabel{eq:NT_Quadratic_min}{{26}{7}{Problem Statement and Dataset Generation}{equation.3.26}{}}
\newlabel{eq:gradient}{{27}{7}{Problem Statement and Dataset Generation}{equation.3.27}{}}
\newlabel{eq:NT_Quadratic_min_gradient_form}{{28}{7}{Problem Statement and Dataset Generation}{equation.3.28}{}}
\newlabel{eq:NT_learning_rate}{{29}{7}{Problem Statement and Dataset Generation}{equation.3.29}{}}
\newlabel{eq:NT_Displacement}{{30}{7}{Problem Statement and Dataset Generation}{equation.3.30}{}}
\citation{zeiler2012adadelta}
\citation{mills2017deep}
\citation{kingma2014adam}
\citation{goodfellow2016deep}
\newlabel{eq:NT_Stochastic}{{31}{8}{Problem Statement and Dataset Generation}{equation.3.31}{}}
\newlabel{eq:NT_weight_bias_update}{{32}{8}{Problem Statement and Dataset Generation}{equation.3.32}{}}
\citation{mills2017deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dataset and Dataset Generation}{9}{subsection.3.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:a}{{1a}{9}{g = 0\relax }{figure.caption.3}{}}
\newlabel{sub@fig:a}{{a}{9}{g = 0\relax }{figure.caption.3}{}}
\newlabel{fig:b}{{1b}{9}{g = 0.1\relax }{figure.caption.3}{}}
\newlabel{sub@fig:b}{{b}{9}{g = 0.1\relax }{figure.caption.3}{}}
\newlabel{fig:c}{{1c}{9}{g = 1\relax }{figure.caption.3}{}}
\newlabel{sub@fig:c}{{c}{9}{g = 1\relax }{figure.caption.3}{}}
\newlabel{fig:d}{{1d}{9}{g = 10\relax }{figure.caption.3}{}}
\newlabel{sub@fig:d}{{d}{9}{g = 10\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Histograms represents total energy distributions for different interaction parameter values.\relax }}{9}{figure.caption.3}}
\newlabel{fig:energy_dist}{{1}{9}{Histograms represents total energy distributions for different interaction parameter values.\relax }{figure.caption.3}{}}
\citation{paszke2017automatic}
\citation{goodfellow2016deep}
\citation{mills2017deep}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces CAPTION\relax }}{10}{table.caption.4}}
\newlabel{my-label}{{1}{10}{CAPTION\relax }{table.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Machine Learning for GPE}{10}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Architecture}{10}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Hyperparameters}{11}{subsection.4.2}}
\newlabel{fig:a}{{2a}{11}{FCN[128, 40, 40, 1], $\eta $ = 0.003\relax }{figure.caption.5}{}}
\newlabel{sub@fig:a}{{a}{11}{FCN[128, 40, 40, 1], $\eta $ = 0.003\relax }{figure.caption.5}{}}
\newlabel{fig:b}{{2b}{11}{FCN[128, 40, 40, 1], $\eta $ = 0.001\relax }{figure.caption.5}{}}
\newlabel{sub@fig:b}{{b}{11}{FCN[128, 40, 40, 1], $\eta $ = 0.001\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Here both figures represent True Energy of Ground State (unit) vs Predicted Ground State Energy (unit). Their hyperparameters are identical except learning rate. Total number of epoch is 20 and batch size is 10. In this example interaction parameter $g$, is zero. Even learning rate 0.001 seems more precise, it is trivial to expect that change in interaction parameter will effect the result. \relax }}{11}{figure.caption.5}}
\newlabel{fig:a}{{3a}{12}{FCN[128, 40, 40, 1], lr = 0.003\relax }{figure.caption.6}{}}
\newlabel{sub@fig:a}{{a}{12}{FCN[128, 40, 40, 1], lr = 0.003\relax }{figure.caption.6}{}}
\newlabel{fig:b}{{3b}{12}{FCN[128, 40, 40, 1], lr = 0.001\relax }{figure.caption.6}{}}
\newlabel{sub@fig:b}{{b}{12}{FCN[128, 40, 40, 1], lr = 0.001\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Here, interaction parameter, g is 10. It is clear that precision of the network with learning rate 0.003 is higher than 0.001. Of course, dramatic increase in the training dataset length may affect them both to converge same precision but our intention here to show that small change in learning rate causes different results.\relax }}{12}{figure.caption.6}}
\newlabel{fig:a}{{4a}{12}{FCN[128, 30, 30, 10, 1]\relax }{figure.caption.7}{}}
\newlabel{sub@fig:a}{{a}{12}{FCN[128, 30, 30, 10, 1]\relax }{figure.caption.7}{}}
\newlabel{fig:b}{{4b}{12}{FCN[128, 40, 40, 1]\relax }{figure.caption.7}{}}
\newlabel{sub@fig:b}{{b}{12}{FCN[128, 40, 40, 1]\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Here interaction paramater $g$, is again 10. Batch size is 10 and total number of epoch is 20 for this example. Precision of the network of 5 layer (a) is higher than 4 layer (b). Bias in (a) can be eliminated by increasing training dataset length.\relax }}{12}{figure.caption.7}}
\newlabel{fig:network_layer_increment}{{4}{12}{Here interaction paramater $g$, is again 10. Batch size is 10 and total number of epoch is 20 for this example. Precision of the network of 5 layer (a) is higher than 4 layer (b). Bias in (a) can be eliminated by increasing training dataset length.\relax }{figure.caption.7}{}}
\newlabel{fig:a}{{5a}{13}{FCN[128, 30, 30, 10, 1]\relax }{figure.caption.8}{}}
\newlabel{sub@fig:a}{{a}{13}{FCN[128, 30, 30, 10, 1]\relax }{figure.caption.8}{}}
\newlabel{fig:b}{{5b}{13}{FCN[128, 40, 40, 1]\relax }{figure.caption.8}{}}
\newlabel{sub@fig:b}{{b}{13}{FCN[128, 40, 40, 1]\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Total training dataset length is increased to 3500 and test dataset length is 500. Batch size, Learning rate are same as example given in Fig.\nobreakspace  {}\ref  {fig:network_layer_increment} but the epoch is 30. The bias is eliminated. Precision and accuracy of the network of 5 layers is sufficient.\relax }}{13}{figure.caption.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Training Results}{13}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Non-interacting System}{13}{subsubsection.4.3.1}}
\newlabel{fig:a}{{6a}{14}{Epoch = 20\relax }{figure.caption.9}{}}
\newlabel{sub@fig:a}{{a}{14}{Epoch = 20\relax }{figure.caption.9}{}}
\newlabel{fig:b}{{6b}{14}{Epoch = 40\relax }{figure.caption.9}{}}
\newlabel{sub@fig:b}{{b}{14}{Epoch = 40\relax }{figure.caption.9}{}}
\newlabel{fig:c}{{6c}{14}{Epoch = 60\relax }{figure.caption.9}{}}
\newlabel{sub@fig:c}{{c}{14}{Epoch = 60\relax }{figure.caption.9}{}}
\newlabel{fig:d}{{6d}{14}{Loss\relax }{figure.caption.9}{}}
\newlabel{sub@fig:d}{{d}{14}{Loss\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces In figures, $x$ axis represents true dimensionless total energy values, and $y$ is predicted energy by trained network. Inset histogram at the left upper corner is relative error given as percentage and the inset histogram at the right corner is difference error.\relax }}{14}{figure.caption.9}}
\newlabel{fig:FFN-g-0}{{6}{14}{In figures, $x$ axis represents true dimensionless total energy values, and $y$ is predicted energy by trained network. Inset histogram at the left upper corner is relative error given as percentage and the inset histogram at the right corner is difference error.\relax }{figure.caption.9}{}}
\newlabel{fig:a}{{7a}{15}{Epoch = 20\relax }{figure.caption.10}{}}
\newlabel{sub@fig:a}{{a}{15}{Epoch = 20\relax }{figure.caption.10}{}}
\newlabel{fig:b}{{7b}{15}{Epoch = 40\relax }{figure.caption.10}{}}
\newlabel{sub@fig:b}{{b}{15}{Epoch = 40\relax }{figure.caption.10}{}}
\newlabel{fig:c}{{7c}{15}{Epoch = 60\relax }{figure.caption.10}{}}
\newlabel{sub@fig:c}{{c}{15}{Epoch = 60\relax }{figure.caption.10}{}}
\newlabel{fig:c}{{7d}{15}{Loss\relax }{figure.caption.10}{}}
\newlabel{sub@fig:c}{{d}{15}{Loss\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces CNN results for $g = 0$\relax }}{15}{figure.caption.10}}
\newlabel{fig:CNN-g-0}{{7}{15}{CNN results for $g = 0$\relax }{figure.caption.10}{}}
\citation{barenghi2016primer}
\newlabel{fig:a}{{8a}{16}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.11}{}}
\newlabel{sub@fig:a}{{a}{16}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.11}{}}
\newlabel{fig:b}{{8b}{16}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.11}{}}
\newlabel{sub@fig:b}{{b}{16}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.11}{}}
\newlabel{fig:c}{{8c}{16}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.11}{}}
\newlabel{sub@fig:c}{{c}{16}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.11}{}}
\newlabel{fig:c}{{8d}{16}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.11}{}}
\newlabel{sub@fig:c}{{d}{16}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces FCN[128, 30, 30, 10, 4] results for $g = 0$. Here (a) is interaction energy, (b) potential energy, (c) kinetic energy and (d) total energy predictions.\relax }}{16}{figure.caption.11}}
\newlabel{fig:FFN-g-0-S}{{8}{16}{FCN[128, 30, 30, 10, 4] results for $g = 0$. Here (a) is interaction energy, (b) potential energy, (c) kinetic energy and (d) total energy predictions.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Interacting Systems}{16}{subsubsection.4.3.2}}
\newlabel{fig:a}{{9a}{17}{Epoch = 20\relax }{figure.caption.12}{}}
\newlabel{sub@fig:a}{{a}{17}{Epoch = 20\relax }{figure.caption.12}{}}
\newlabel{fig:b}{{9b}{17}{Epoch = 40\relax }{figure.caption.12}{}}
\newlabel{sub@fig:b}{{b}{17}{Epoch = 40\relax }{figure.caption.12}{}}
\newlabel{fig:c}{{9c}{17}{Epoch = 60\relax }{figure.caption.12}{}}
\newlabel{sub@fig:c}{{c}{17}{Epoch = 60\relax }{figure.caption.12}{}}
\newlabel{fig:c}{{9d}{17}{Loss\relax }{figure.caption.12}{}}
\newlabel{sub@fig:c}{{d}{17}{Loss\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces FCN[128, 30, 30, 10, 1] results for $g = 0.1$.\relax }}{17}{figure.caption.12}}
\newlabel{fig:FFN-g-0.1}{{9}{17}{FCN[128, 30, 30, 10, 1] results for $g = 0.1$.\relax }{figure.caption.12}{}}
\newlabel{fig:a}{{10a}{18}{Conv1D\relax }{figure.caption.13}{}}
\newlabel{sub@fig:a}{{a}{18}{Conv1D\relax }{figure.caption.13}{}}
\newlabel{fig:b}{{10b}{18}{Conv1D\relax }{figure.caption.13}{}}
\newlabel{sub@fig:b}{{b}{18}{Conv1D\relax }{figure.caption.13}{}}
\newlabel{fig:c}{{10c}{18}{Conv1D\relax }{figure.caption.13}{}}
\newlabel{sub@fig:c}{{c}{18}{Conv1D\relax }{figure.caption.13}{}}
\newlabel{fig:c}{{10d}{18}{Conv1D\relax }{figure.caption.13}{}}
\newlabel{sub@fig:c}{{d}{18}{Conv1D\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces CNN results for $g = 0.1$\relax }}{18}{figure.caption.13}}
\newlabel{fig:CNN-g-0.1}{{10}{18}{CNN results for $g = 0.1$\relax }{figure.caption.13}{}}
\newlabel{fig:a}{{11a}{19}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.14}{}}
\newlabel{sub@fig:a}{{a}{19}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.14}{}}
\newlabel{fig:b}{{11b}{19}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.14}{}}
\newlabel{sub@fig:b}{{b}{19}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.14}{}}
\newlabel{fig:c}{{11c}{19}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.14}{}}
\newlabel{sub@fig:c}{{c}{19}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.14}{}}
\newlabel{fig:c}{{11d}{19}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.14}{}}
\newlabel{sub@fig:c}{{d}{19}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Separate Energy Predictions for $g = 0.1$ \relax }}{19}{figure.caption.14}}
\newlabel{fig:FFN-g-0.1-S}{{11}{19}{Separate Energy Predictions for $g = 0.1$ \relax }{figure.caption.14}{}}
\newlabel{fig:a}{{12a}{20}{Epoch = 20\relax }{figure.caption.15}{}}
\newlabel{sub@fig:a}{{a}{20}{Epoch = 20\relax }{figure.caption.15}{}}
\newlabel{fig:b}{{12b}{20}{Epoch = 40\relax }{figure.caption.15}{}}
\newlabel{sub@fig:b}{{b}{20}{Epoch = 40\relax }{figure.caption.15}{}}
\newlabel{fig:c}{{12c}{20}{Epoch = 60\relax }{figure.caption.15}{}}
\newlabel{sub@fig:c}{{c}{20}{Epoch = 60\relax }{figure.caption.15}{}}
\newlabel{fig:c}{{12d}{20}{Loss\relax }{figure.caption.15}{}}
\newlabel{sub@fig:c}{{d}{20}{Loss\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces FCN[128, 30, 30, 10, 1] results for $g = 1$\relax }}{20}{figure.caption.15}}
\newlabel{fig:FFN-g-1}{{12}{20}{FCN[128, 30, 30, 10, 1] results for $g = 1$\relax }{figure.caption.15}{}}
\newlabel{fig:a}{{13a}{21}{Epoch = 20\relax }{figure.caption.16}{}}
\newlabel{sub@fig:a}{{a}{21}{Epoch = 20\relax }{figure.caption.16}{}}
\newlabel{fig:b}{{13b}{21}{Epoch = 40\relax }{figure.caption.16}{}}
\newlabel{sub@fig:b}{{b}{21}{Epoch = 40\relax }{figure.caption.16}{}}
\newlabel{fig:c}{{13c}{21}{Epoch = 60\relax }{figure.caption.16}{}}
\newlabel{sub@fig:c}{{c}{21}{Epoch = 60\relax }{figure.caption.16}{}}
\newlabel{fig:c}{{13d}{21}{Loss\relax }{figure.caption.16}{}}
\newlabel{sub@fig:c}{{d}{21}{Loss\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces CNN results for $g = 1$\relax }}{21}{figure.caption.16}}
\newlabel{fig:CNN-g-1}{{13}{21}{CNN results for $g = 1$\relax }{figure.caption.16}{}}
\newlabel{fig:a}{{14a}{22}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.17}{}}
\newlabel{sub@fig:a}{{a}{22}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.17}{}}
\newlabel{fig:b}{{14b}{22}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.17}{}}
\newlabel{sub@fig:b}{{b}{22}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.17}{}}
\newlabel{fig:c}{{14c}{22}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.17}{}}
\newlabel{sub@fig:c}{{c}{22}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.17}{}}
\newlabel{fig:c}{{14d}{22}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.17}{}}
\newlabel{sub@fig:c}{{d}{22}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces FCN[128, 30, 30, 10, 4], Separate energy predictions for $g = 1$.\relax }}{22}{figure.caption.17}}
\newlabel{fig:FFN-g-1-S}{{14}{22}{FCN[128, 30, 30, 10, 4], Separate energy predictions for $g = 1$.\relax }{figure.caption.17}{}}
\newlabel{fig:a}{{15a}{23}{Epoch = 20\relax }{figure.caption.18}{}}
\newlabel{sub@fig:a}{{a}{23}{Epoch = 20\relax }{figure.caption.18}{}}
\newlabel{fig:b}{{15b}{23}{Epoch = 40\relax }{figure.caption.18}{}}
\newlabel{sub@fig:b}{{b}{23}{Epoch = 40\relax }{figure.caption.18}{}}
\newlabel{fig:c}{{15c}{23}{Epoch = 60\relax }{figure.caption.18}{}}
\newlabel{sub@fig:c}{{c}{23}{Epoch = 60\relax }{figure.caption.18}{}}
\newlabel{fig:c}{{15d}{23}{Loss\relax }{figure.caption.18}{}}
\newlabel{sub@fig:c}{{d}{23}{Loss\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces FCN[128, 30, 30, 10, 1] predictions for $g = 10$\relax }}{23}{figure.caption.18}}
\newlabel{fig:FFN-g-10}{{15}{23}{FCN[128, 30, 30, 10, 1] predictions for $g = 10$\relax }{figure.caption.18}{}}
\newlabel{fig:a}{{16a}{24}{Epoch = 20\relax }{figure.caption.19}{}}
\newlabel{sub@fig:a}{{a}{24}{Epoch = 20\relax }{figure.caption.19}{}}
\newlabel{fig:b}{{16b}{24}{Epoch = 40\relax }{figure.caption.19}{}}
\newlabel{sub@fig:b}{{b}{24}{Epoch = 40\relax }{figure.caption.19}{}}
\newlabel{fig:c}{{16c}{24}{Epoch = 60\relax }{figure.caption.19}{}}
\newlabel{sub@fig:c}{{c}{24}{Epoch = 60\relax }{figure.caption.19}{}}
\newlabel{fig:c}{{16d}{24}{Loss\relax }{figure.caption.19}{}}
\newlabel{sub@fig:c}{{d}{24}{Loss\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces CNN results for $g = 10$\relax }}{24}{figure.caption.19}}
\newlabel{fig:CNN-g-10}{{16}{24}{CNN results for $g = 10$\relax }{figure.caption.19}{}}
\newlabel{fig:a}{{17a}{25}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.20}{}}
\newlabel{sub@fig:a}{{a}{25}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.20}{}}
\newlabel{fig:b}{{17b}{25}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.20}{}}
\newlabel{sub@fig:b}{{b}{25}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.20}{}}
\newlabel{fig:c}{{17c}{25}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.20}{}}
\newlabel{sub@fig:c}{{c}{25}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.20}{}}
\newlabel{fig:c}{{17d}{25}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.20}{}}
\newlabel{sub@fig:c}{{d}{25}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Separate prediction g=10\relax }}{25}{figure.caption.20}}
\newlabel{fig:FFN-g-10-S}{{17}{25}{Separate prediction g=10\relax }{figure.caption.20}{}}
\newlabel{fig:a}{{18a}{26}{Epoch = 20\relax }{figure.caption.21}{}}
\newlabel{sub@fig:a}{{a}{26}{Epoch = 20\relax }{figure.caption.21}{}}
\newlabel{fig:b}{{18b}{26}{Epoch = 40\relax }{figure.caption.21}{}}
\newlabel{sub@fig:b}{{b}{26}{Epoch = 40\relax }{figure.caption.21}{}}
\newlabel{fig:c}{{18c}{26}{Epoch = 60\relax }{figure.caption.21}{}}
\newlabel{sub@fig:c}{{c}{26}{Epoch = 60\relax }{figure.caption.21}{}}
\newlabel{fig:c}{{18d}{26}{Loss\relax }{figure.caption.21}{}}
\newlabel{sub@fig:c}{{d}{26}{Loss\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces FCN[128, 30, 30, 10, 1] predictions for g = 20\relax }}{26}{figure.caption.21}}
\newlabel{fig:FFN-g-20}{{18}{26}{FCN[128, 30, 30, 10, 1] predictions for g = 20\relax }{figure.caption.21}{}}
\newlabel{fig:a}{{19a}{27}{Conv1D\relax }{figure.caption.22}{}}
\newlabel{sub@fig:a}{{a}{27}{Conv1D\relax }{figure.caption.22}{}}
\newlabel{fig:b}{{19b}{27}{Conv1D\relax }{figure.caption.22}{}}
\newlabel{sub@fig:b}{{b}{27}{Conv1D\relax }{figure.caption.22}{}}
\newlabel{fig:c}{{19c}{27}{Conv1D\relax }{figure.caption.22}{}}
\newlabel{sub@fig:c}{{c}{27}{Conv1D\relax }{figure.caption.22}{}}
\newlabel{fig:d}{{19d}{27}{Conv1D\relax }{figure.caption.22}{}}
\newlabel{sub@fig:d}{{d}{27}{Conv1D\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces CNN predictions for $g = 20$\relax }}{27}{figure.caption.22}}
\newlabel{fig:CNN-g-20}{{19}{27}{CNN predictions for $g = 20$\relax }{figure.caption.22}{}}
\newlabel{fig:a}{{20a}{28}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.23}{}}
\newlabel{sub@fig:a}{{a}{28}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.23}{}}
\newlabel{fig:b}{{20b}{28}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.23}{}}
\newlabel{sub@fig:b}{{b}{28}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.23}{}}
\newlabel{fig:c}{{20c}{28}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.23}{}}
\newlabel{sub@fig:c}{{c}{28}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.23}{}}
\newlabel{fig:c}{{20d}{28}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.23}{}}
\newlabel{sub@fig:c}{{d}{28}{FCN[128, 30, 30, 10, 4]\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Separate prediction g=20\relax }}{28}{figure.caption.23}}
\newlabel{fig:FFN-g-20-S}{{20}{28}{Separate prediction g=20\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Inverse Problem Prediction of ${g}$}{28}{subsubsection.4.3.3}}
\newlabel{fig:a}{{21a}{29}{Epoch = 30\relax }{figure.caption.24}{}}
\newlabel{sub@fig:a}{{a}{29}{Epoch = 30\relax }{figure.caption.24}{}}
\newlabel{fig:b}{{21b}{29}{Epoch = 30\relax }{figure.caption.24}{}}
\newlabel{sub@fig:b}{{b}{29}{Epoch = 30\relax }{figure.caption.24}{}}
\newlabel{fig:c}{{21c}{29}{Epoch = 30\relax }{figure.caption.24}{}}
\newlabel{sub@fig:c}{{c}{29}{Epoch = 30\relax }{figure.caption.24}{}}
\newlabel{fig:d}{{21d}{29}{Loss\relax }{figure.caption.24}{}}
\newlabel{sub@fig:d}{{d}{29}{Loss\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces In (a) is angular frequency is fixed and there is no shift (FPFS). In (b) angular frequency is randomized and no shift (VPFS). In (c) both angular frequency and shift are randomized (VPVS).\relax }}{29}{figure.caption.24}}
\newlabel{fig:FFN-g-pred}{{21}{29}{In (a) is angular frequency is fixed and there is no shift (FPFS). In (b) angular frequency is randomized and no shift (VPFS). In (c) both angular frequency and shift are randomized (VPVS).\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{30}{section.5}}
\bibstyle{ieeetr}
\bibdata{references}
\bibcite{nielsen2015neural}{1}
\bibcite{physicsml}{2}
\bibcite{carleo2017solving}{3}
\bibcite{cai2017approximating}{4}
\bibcite{wang2016discovering}{5}
\bibcite{stoudenmire2016supervised}{6}
\bibcite{biamonte1611quantum}{7}
\bibcite{mills2017deep}{8}
\bibcite{barenghi2016primer}{9}
\bibcite{dennis2013xmds2}{10}
\bibcite{muruganandam2009fortran}{11}
\bibcite{zimmermann2011comparison}{12}
\bibcite{zeiler2012adadelta}{13}
\bibcite{kingma2014adam}{14}
\bibcite{goodfellow2016deep}{15}
\bibcite{paszke2017automatic}{16}
\@writefile{toc}{\contentsline {section}{\numberline {A}APPENDIX A}{32}{appendix.A}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Comment on Python Codes}{32}{subsection.A.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Neural Network and Utility Codes}{32}{subsection.A.2}}
\gdef\minted@oldcachelist{,
  default-pyg-prefix.pygstyle,
  default.pygstyle,
  C58E9BBB40E6DDF658B16975577A6C595D6DDC1AEC8E33BE4D7FE68C664CFB8D.pygtex,
  CAC05E19BEB9A35060C7E924975B132E51B886C5254A146A5A4ACA843E6B6696.pygtex,
  5E7739CE35DDCEB2740771C7175FA9054027BB9E368CD6D9B4F08D7D409F1BBF.pygtex,
  218FE62500BBB4C5896D60288D559D7F594849E7AB51E3A2252ED142A23CFEE3.pygtex,
  ED0DDAD16A889E05F9FE7D5D5069117AA618E7CB519521183C477A254ADE907D.pygtex,
  43E90FAF3B3788B1742C2DFE2DC33B8C85CDDE5A4BF9C78030152946E88C1534.pygtex}
