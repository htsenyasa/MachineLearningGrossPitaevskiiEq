\relax 
\providecommand{\transparent@use}[1]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Gross Pitaevskii Equation}{1}{section.2}}
\newlabel{eq:GPE_3D}{{1}{1}{Gross Pitaevskii Equation}{equation.2.1}{}}
\newlabel{eq:GPE_inter_param}{{2}{1}{Gross Pitaevskii Equation}{equation.2.2}{}}
\newlabel{eq:GPE_harmonic_potential}{{3}{1}{Gross Pitaevskii Equation}{equation.2.3}{}}
\newlabel{eq:GPE_time_indep_wave_func}{{4}{1}{Gross Pitaevskii Equation}{equation.2.4}{}}
\newlabel{eq:GPE_time_indep}{{5}{2}{Gross Pitaevskii Equation}{equation.2.5}{}}
\newlabel{eq:GPE_time_indep_wave_func_seperated}{{6}{2}{Gross Pitaevskii Equation}{equation.2.6}{}}
\newlabel{eq:GPE_1D}{{7}{2}{Gross Pitaevskii Equation}{equation.2.7}{}}
\newlabel{eq:GPE_1D_chem_inter}{{8}{2}{Gross Pitaevskii Equation}{equation.2.8}{}}
\newlabel{eq:GPE_dimensionless_length}{{9}{2}{Gross Pitaevskii Equation}{equation.2.9}{}}
\newlabel{eq:GPE_dimensionless_energy}{{10}{2}{Gross Pitaevskii Equation}{equation.2.10}{}}
\newlabel{eq:GPE_dimensionless_without_g}{{11}{2}{Gross Pitaevskii Equation}{equation.2.11}{}}
\newlabel{eq:GPE_dimensionless_g_1}{{13}{3}{Gross Pitaevskii Equation}{equation.2.13}{}}
\newlabel{eq:GPE_dimensionless_g_2}{{14}{3}{Gross Pitaevskii Equation}{equation.2.14}{}}
\newlabel{eq:GPE_dimensionless}{{15}{3}{Gross Pitaevskii Equation}{equation.2.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Types of Potentials}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Analytical Solution and Approximation}{3}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Numerical Solution and XMDS Framework}{3}{subsection.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Problem Statements and Dataset Generation}{3}{section.3}}
\newlabel{eq:NU_neuron}{{16}{4}{Problem Statements and Dataset Generation}{equation.3.16}{}}
\newlabel{eq:NU_step_function}{{17}{4}{Problem Statements and Dataset Generation}{equation.3.17}{}}
\newlabel{eq:NU_sigma_function}{{18}{5}{Problem Statements and Dataset Generation}{equation.3.18}{}}
\newlabel{eq:NU_neuron_connection}{{19}{5}{Problem Statements and Dataset Generation}{equation.3.19}{}}
\newlabel{eq:NT_Quadratic}{{20}{5}{Problem Statements and Dataset Generation}{equation.3.20}{}}
\newlabel{eq:NT_Quadratic_min}{{21}{6}{Problem Statements and Dataset Generation}{equation.3.21}{}}
\newlabel{eq:gradient}{{22}{6}{Problem Statements and Dataset Generation}{equation.3.22}{}}
\newlabel{eq:NT_Quadratic_min_gradient_form}{{23}{6}{Problem Statements and Dataset Generation}{equation.3.23}{}}
\newlabel{eq:NT_learning_rate}{{24}{6}{Problem Statements and Dataset Generation}{equation.3.24}{}}
\newlabel{eq:NT_Displacement}{{25}{6}{Problem Statements and Dataset Generation}{equation.3.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dataset and Dataset Generation}{7}{subsection.3.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:a}{{1a}{7}{g = 0\relax }{figure.caption.2}{}}
\newlabel{sub@fig:a}{{a}{7}{g = 0\relax }{figure.caption.2}{}}
\newlabel{fig:b}{{1b}{7}{g = 0.1\relax }{figure.caption.2}{}}
\newlabel{sub@fig:b}{{b}{7}{g = 0.1\relax }{figure.caption.2}{}}
\newlabel{fig:c}{{1c}{7}{g = 1\relax }{figure.caption.2}{}}
\newlabel{sub@fig:c}{{c}{7}{g = 1\relax }{figure.caption.2}{}}
\newlabel{fig:d}{{1d}{7}{g = 10\relax }{figure.caption.2}{}}
\newlabel{sub@fig:d}{{d}{7}{g = 10\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax }}{7}{figure.caption.2}}
\newlabel{fig:energy_dist}{{1}{7}{\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Machine Learning for NLSE}{8}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Architecture}{8}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Hyperparameters}{8}{subsection.4.2}}
\newlabel{fig:a}{{2a}{9}{FNN[128, 40, 40, 1], $\eta $ = 0.003\relax }{figure.caption.3}{}}
\newlabel{sub@fig:a}{{a}{9}{FNN[128, 40, 40, 1], $\eta $ = 0.003\relax }{figure.caption.3}{}}
\newlabel{fig:b}{{2b}{9}{FNN[128, 40, 40, 1], $\eta $ = 0.001\relax }{figure.caption.3}{}}
\newlabel{sub@fig:b}{{b}{9}{FNN[128, 40, 40, 1], $\eta $ = 0.001\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Here both figures represent True Energy of Ground State (unit) vs Predicted Ground State Energy (unit). Their hyperparameters are identical except learning rate. Total number of epoch is 20 and batch size is 10. In this example interaction parameter $g$, is zero. Even learning rate 0.001 seems more precise, it is trivial to expect that change in interaction parameter will effect the result. \relax }}{9}{figure.caption.3}}
\newlabel{fig:a}{{3a}{9}{FNN[128, 40, 40, 1], lr = 0.003\relax }{figure.caption.4}{}}
\newlabel{sub@fig:a}{{a}{9}{FNN[128, 40, 40, 1], lr = 0.003\relax }{figure.caption.4}{}}
\newlabel{fig:b}{{3b}{9}{FNN[128, 40, 40, 1], lr = 0.001\relax }{figure.caption.4}{}}
\newlabel{sub@fig:b}{{b}{9}{FNN[128, 40, 40, 1], lr = 0.001\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Here, interaction parameter, g is 10. It is clear that precision of the network with learning rate 0.003 is higher than 0.001. Of course, dramatic increase in the training dataset length may affect them both to converge same precision but our intention here to show that small change in learning rate causes different results.\relax }}{9}{figure.caption.4}}
\newlabel{fig:a}{{4a}{10}{FNN[128, 30, 30, 10, 1]\relax }{figure.caption.5}{}}
\newlabel{sub@fig:a}{{a}{10}{FNN[128, 30, 30, 10, 1]\relax }{figure.caption.5}{}}
\newlabel{fig:b}{{4b}{10}{FNN[128, 40, 40, 1]\relax }{figure.caption.5}{}}
\newlabel{sub@fig:b}{{b}{10}{FNN[128, 40, 40, 1]\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Here interaction paramater $g$, is again 10. Batch size is 10 and total number of epoch is 20 for this example. Precision of the network of 5 layer (a) is higher than 4 layer (b). Bias in (a) can be eliminated by increasing training dataset length.\relax }}{10}{figure.caption.5}}
\newlabel{fig:network_layer_increment}{{4}{10}{Here interaction paramater $g$, is again 10. Batch size is 10 and total number of epoch is 20 for this example. Precision of the network of 5 layer (a) is higher than 4 layer (b). Bias in (a) can be eliminated by increasing training dataset length.\relax }{figure.caption.5}{}}
\newlabel{fig:a}{{5a}{10}{FNN[128, 30, 30, 10, 1]\relax }{figure.caption.6}{}}
\newlabel{sub@fig:a}{{a}{10}{FNN[128, 30, 30, 10, 1]\relax }{figure.caption.6}{}}
\newlabel{fig:b}{{5b}{10}{FNN[128, 40, 40, 1]\relax }{figure.caption.6}{}}
\newlabel{sub@fig:b}{{b}{10}{FNN[128, 40, 40, 1]\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Total training dataset length is increased to 3500 and test dataset length is 500. Batch size, Learning rate are same as example given in Fig.\nobreakspace  {}\ref  {fig:network_layer_increment} but the epoch is 30. The bias is eliminated. Precision and accuracy of the network of 5 layers is sufficient.\relax }}{10}{figure.caption.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Training Results}{11}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Non-interacting System}{11}{subsubsection.4.3.1}}
\newlabel{fig:a}{{\caption@xref {fig:a}{ on input line 415}}{11}{Non-interacting System}{figure.caption.7}{}}
\newlabel{sub@fig:a}{{}{11}{Non-interacting System}{figure.caption.7}{}}
\newlabel{fig:b}{{\caption@xref {fig:b}{ on input line 421}}{11}{Non-interacting System}{figure.caption.7}{}}
\newlabel{sub@fig:b}{{}{11}{Non-interacting System}{figure.caption.7}{}}
\newlabel{fig:c}{{\caption@xref {fig:c}{ on input line 427}}{11}{Non-interacting System}{figure.caption.7}{}}
\newlabel{sub@fig:c}{{}{11}{Non-interacting System}{figure.caption.7}{}}
\newlabel{fig:d}{{\caption@xref {fig:d}{ on input line 433}}{11}{Non-interacting System}{figure.caption.7}{}}
\newlabel{sub@fig:d}{{}{11}{Non-interacting System}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Since the system has no interaction parameter, problem is relatively easy when it is compared to systems that involve interaction. In (a) it is obvious network requires more training example and it reaches a satisfactory level in (b). After that, supplying 20 more epochs nearly does not effect the prediction accuracy.\relax }}{11}{figure.caption.7}}
\newlabel{fig:FFN-g-0}{{6}{11}{Since the system has no interaction parameter, problem is relatively easy when it is compared to systems that involve interaction. In (a) it is obvious network requires more training example and it reaches a satisfactory level in (b). After that, supplying 20 more epochs nearly does not effect the prediction accuracy.\relax }{figure.caption.7}{}}
\newlabel{fig:a}{{7a}{12}{Conv1D\relax }{figure.caption.8}{}}
\newlabel{sub@fig:a}{{a}{12}{Conv1D\relax }{figure.caption.8}{}}
\newlabel{fig:b}{{7b}{12}{Conv1D\relax }{figure.caption.8}{}}
\newlabel{sub@fig:b}{{b}{12}{Conv1D\relax }{figure.caption.8}{}}
\newlabel{fig:c}{{7c}{12}{Conv1D\relax }{figure.caption.8}{}}
\newlabel{sub@fig:c}{{c}{12}{Conv1D\relax }{figure.caption.8}{}}
\newlabel{fig:c}{{7d}{12}{Conv1D\relax }{figure.caption.8}{}}
\newlabel{sub@fig:c}{{d}{12}{Conv1D\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Accuracy of the CNN is higher than FFN in first 20 epochs. In (a) there is no bias as in Fig.\nobreakspace  {}\ref  {fig:FFN-g-0}\relax }}{12}{figure.caption.8}}
\newlabel{fig:a}{{8a}{13}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.9}{}}
\newlabel{sub@fig:a}{{a}{13}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.9}{}}
\newlabel{fig:b}{{8b}{13}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.9}{}}
\newlabel{sub@fig:b}{{b}{13}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.9}{}}
\newlabel{fig:c}{{8c}{13}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.9}{}}
\newlabel{sub@fig:c}{{c}{13}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.9}{}}
\newlabel{fig:c}{{8d}{13}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.9}{}}
\newlabel{sub@fig:c}{{d}{13}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Here (a) is interaction energy, (b) potential energy, (c) kinetic energy and (d) total energy predictions. Only number of neurons in the output layer increased to 4, and still network predicts total energy of the system within same sensitivity as former FNN network.\relax }}{13}{figure.caption.9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Interacting Systems}{13}{subsubsection.4.3.2}}
\newlabel{fig:a}{{9a}{14}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.10}{}}
\newlabel{sub@fig:a}{{a}{14}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.10}{}}
\newlabel{fig:b}{{9b}{14}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.10}{}}
\newlabel{sub@fig:b}{{b}{14}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.10}{}}
\newlabel{fig:c}{{9c}{14}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.10}{}}
\newlabel{sub@fig:c}{{c}{14}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.10}{}}
\newlabel{fig:c}{{9d}{14}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.10}{}}
\newlabel{sub@fig:c}{{d}{14}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces In first 20 epoch (a), there are relatively higher deviations in lower energies. In (b), deviations become smaller but still visible. In (c), prediction line is smoother but still deviations remains in lowest energy levels.\relax }}{14}{figure.caption.10}}
\newlabel{fig:a}{{10a}{15}{Conv1D\relax }{figure.caption.11}{}}
\newlabel{sub@fig:a}{{a}{15}{Conv1D\relax }{figure.caption.11}{}}
\newlabel{fig:b}{{10b}{15}{Conv1D\relax }{figure.caption.11}{}}
\newlabel{sub@fig:b}{{b}{15}{Conv1D\relax }{figure.caption.11}{}}
\newlabel{fig:c}{{10c}{15}{Conv1D\relax }{figure.caption.11}{}}
\newlabel{sub@fig:c}{{c}{15}{Conv1D\relax }{figure.caption.11}{}}
\newlabel{fig:c}{{10d}{15}{Conv1D\relax }{figure.caption.11}{}}
\newlabel{sub@fig:c}{{d}{15}{Conv1D\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces In (a) deviation has nearly same characteristic with FNN in lower energies. After 60 epochs (c), there is a visible shift in higher energies (after 0.7 (unit)) but this does not occur in (b). MSE also shows this fact since its order reduces.\relax }}{15}{figure.caption.11}}
\newlabel{fig:a}{{11a}{16}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.12}{}}
\newlabel{sub@fig:a}{{a}{16}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.12}{}}
\newlabel{fig:b}{{11b}{16}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.12}{}}
\newlabel{sub@fig:b}{{b}{16}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.12}{}}
\newlabel{fig:c}{{11c}{16}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.12}{}}
\newlabel{sub@fig:c}{{c}{16}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.12}{}}
\newlabel{fig:c}{{11d}{16}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.12}{}}
\newlabel{sub@fig:c}{{d}{16}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Notice that, the order of interaction energy is much smaller than the others. This may be the reason of bias in (a). Applying a proper normalization to the variables may reduce the error. \textbf  {REF}\relax }}{16}{figure.caption.12}}
\newlabel{fig:a}{{12a}{17}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.13}{}}
\newlabel{sub@fig:a}{{a}{17}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.13}{}}
\newlabel{fig:b}{{12b}{17}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.13}{}}
\newlabel{sub@fig:b}{{b}{17}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.13}{}}
\newlabel{fig:c}{{12c}{17}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.13}{}}
\newlabel{sub@fig:c}{{c}{17}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.13}{}}
\newlabel{fig:c}{{12d}{17}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.13}{}}
\newlabel{sub@fig:c}{{d}{17}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces g = 1\relax }}{17}{figure.caption.13}}
\newlabel{fig:a}{{13a}{18}{Conv1D\relax }{figure.caption.14}{}}
\newlabel{sub@fig:a}{{a}{18}{Conv1D\relax }{figure.caption.14}{}}
\newlabel{fig:b}{{13b}{18}{Conv1D\relax }{figure.caption.14}{}}
\newlabel{sub@fig:b}{{b}{18}{Conv1D\relax }{figure.caption.14}{}}
\newlabel{fig:c}{{13c}{18}{Conv1D\relax }{figure.caption.14}{}}
\newlabel{sub@fig:c}{{c}{18}{Conv1D\relax }{figure.caption.14}{}}
\newlabel{fig:c}{{13d}{18}{Conv1D\relax }{figure.caption.14}{}}
\newlabel{sub@fig:c}{{d}{18}{Conv1D\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces g = 1\relax }}{18}{figure.caption.14}}
\newlabel{fig:a}{{14a}{19}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.15}{}}
\newlabel{sub@fig:a}{{a}{19}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.15}{}}
\newlabel{fig:b}{{14b}{19}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.15}{}}
\newlabel{sub@fig:b}{{b}{19}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.15}{}}
\newlabel{fig:c}{{14c}{19}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.15}{}}
\newlabel{sub@fig:c}{{c}{19}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.15}{}}
\newlabel{fig:c}{{14d}{19}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.15}{}}
\newlabel{sub@fig:c}{{d}{19}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Separate prediction g=1\relax }}{19}{figure.caption.15}}
\newlabel{fig:a}{{15a}{20}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.16}{}}
\newlabel{sub@fig:a}{{a}{20}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.16}{}}
\newlabel{fig:b}{{15b}{20}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.16}{}}
\newlabel{sub@fig:b}{{b}{20}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.16}{}}
\newlabel{fig:c}{{15c}{20}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.16}{}}
\newlabel{sub@fig:c}{{c}{20}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.16}{}}
\newlabel{fig:c}{{15d}{20}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.16}{}}
\newlabel{sub@fig:c}{{d}{20}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces g = 10\relax }}{20}{figure.caption.16}}
\newlabel{fig:a}{{16a}{21}{Conv1D\relax }{figure.caption.17}{}}
\newlabel{sub@fig:a}{{a}{21}{Conv1D\relax }{figure.caption.17}{}}
\newlabel{fig:b}{{16b}{21}{Conv1D\relax }{figure.caption.17}{}}
\newlabel{sub@fig:b}{{b}{21}{Conv1D\relax }{figure.caption.17}{}}
\newlabel{fig:c}{{16c}{21}{Conv1D\relax }{figure.caption.17}{}}
\newlabel{sub@fig:c}{{c}{21}{Conv1D\relax }{figure.caption.17}{}}
\newlabel{fig:c}{{16d}{21}{Conv1D\relax }{figure.caption.17}{}}
\newlabel{sub@fig:c}{{d}{21}{Conv1D\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces g = 10\relax }}{21}{figure.caption.17}}
\newlabel{fig:a}{{17a}{22}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.18}{}}
\newlabel{sub@fig:a}{{a}{22}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.18}{}}
\newlabel{fig:b}{{17b}{22}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.18}{}}
\newlabel{sub@fig:b}{{b}{22}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.18}{}}
\newlabel{fig:c}{{17c}{22}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.18}{}}
\newlabel{sub@fig:c}{{c}{22}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.18}{}}
\newlabel{fig:c}{{17d}{22}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.18}{}}
\newlabel{sub@fig:c}{{d}{22}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Separate prediction g=10\relax }}{22}{figure.caption.18}}
\newlabel{fig:a}{{18a}{23}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.19}{}}
\newlabel{sub@fig:a}{{a}{23}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.19}{}}
\newlabel{fig:b}{{18b}{23}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.19}{}}
\newlabel{sub@fig:b}{{b}{23}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.19}{}}
\newlabel{fig:c}{{18c}{23}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.19}{}}
\newlabel{sub@fig:c}{{c}{23}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.19}{}}
\newlabel{fig:c}{{18d}{23}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.19}{}}
\newlabel{sub@fig:c}{{d}{23}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces g = 20\relax }}{23}{figure.caption.19}}
\newlabel{fig:a}{{19a}{24}{Conv1D\relax }{figure.caption.20}{}}
\newlabel{sub@fig:a}{{a}{24}{Conv1D\relax }{figure.caption.20}{}}
\newlabel{fig:b}{{19b}{24}{Conv1D\relax }{figure.caption.20}{}}
\newlabel{sub@fig:b}{{b}{24}{Conv1D\relax }{figure.caption.20}{}}
\newlabel{fig:c}{{19c}{24}{Conv1D\relax }{figure.caption.20}{}}
\newlabel{sub@fig:c}{{c}{24}{Conv1D\relax }{figure.caption.20}{}}
\newlabel{fig:d}{{19d}{24}{Conv1D\relax }{figure.caption.20}{}}
\newlabel{sub@fig:d}{{d}{24}{Conv1D\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces g = 20\relax }}{24}{figure.caption.20}}
\newlabel{fig:a}{{20a}{25}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.21}{}}
\newlabel{sub@fig:a}{{a}{25}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.21}{}}
\newlabel{fig:b}{{20b}{25}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.21}{}}
\newlabel{sub@fig:b}{{b}{25}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.21}{}}
\newlabel{fig:c}{{20c}{25}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.21}{}}
\newlabel{sub@fig:c}{{c}{25}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.21}{}}
\newlabel{fig:c}{{20d}{25}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.21}{}}
\newlabel{sub@fig:c}{{d}{25}{FNN[128, 30, 30, 10, 4]\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Separate prediction g=20\relax }}{25}{figure.caption.21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Inverse Problem Prediction of $\boldsymbol  {g}$}{25}{subsubsection.4.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Fixed potential and shift\relax }}{25}{figure.caption.22}}
\newlabel{fig:a}{{21}{25}{Fixed potential and shift\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Various potential and fixed shift\relax }}{26}{figure.caption.23}}
\newlabel{fig:a}{{22}{26}{Various potential and fixed shift\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Various potential and shift\relax }}{26}{figure.caption.24}}
\newlabel{fig:a}{{23}{26}{Various potential and shift\relax }{figure.caption.24}{}}
