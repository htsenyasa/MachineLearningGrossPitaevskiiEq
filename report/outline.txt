Abstract
----
We train an artificial neural network to estimate the ground state energy
of a one-dimensional Bose-Einstein condensate in arbitrary trapping potentials.
Such a system can be described by the solution of a corresponding
Gross-Pitaevskii equation also called a non-linear Schroedinger equation.
We also use the method to predict the non-linearity parameter using the ground
state density profile for any given trapping potential.

I. Introduction
-ML tools are being applied everywhere including the solution of the SE.
-The non-linear SE is ubiquitous in physics.
---
---

II. Gross-Pitaevskii Equation
---
---
    a) Types of potential
	a.0) Homogeneous system (Periodic boundary conditions)
        a.1) Harmonic trap (analytic result available for non-interacting system)
	a.2) Box potential (analytic result available for non-interacting system)

    b) Analytical Solution and Approximations
	b.1) Harmonic
	b.2) Box
        b.3) A variational solution
	b.4) Thomas-Fermi approximation

    c) Numerical Solution and XMDS Framework
        c.1) Details about solution method (short)
            c.2.1) Imaginary Time Evolution (Cite directly from website) // Should it be here or at APPENDIX ?
            c.2.2) Grid and Boundaries
            c.2.3) Sensitivity of solutions and comparision with analytical solutions if it possible. (convince the reader that numerical method works)

        c.2) Implemention using XMDS library
            c.1.1) Mention that potential is generated by XMDS according to given equation if it is not given as vector.
            c.1.2)

IV. Problem statements and dataset generation

    a) Application of ML to estimating ground state energy and non-linearity parameter
    b) GS energy for the non-interacting system (1D version of SE paper)
    c) GS energy of the NLSE in harmonic/box/double well traps
    d) GS energy for random potential
    e) Non-linearity parameter from trapping potential and density profile

V. Machine Learning for NLSE

    a) Pytorch (Short)
        a.1) CPU and GPU  // ??
        a.2) Tensor       // ??

    b) Architecture
        b.1) Fully-connected Feedforward
        b.2) CNN

    c) Hyperparameters of the arch.
        c.1) Learning rate, epoch, batch-size
        c.2) Choice and comparison of different hyper-parameter // (??)

    d) Training
        d.1) How loss changes (Plot)
            d.1.1) Feedforward
            d.1.2) CNN

    e) Results
        e.1) Non-interacting system
            e.1.1) Feedforward
            e.1.2) CNN
        e.2) Interacting system
            e.2.1) Feedforward
            e.2.2) CNN
